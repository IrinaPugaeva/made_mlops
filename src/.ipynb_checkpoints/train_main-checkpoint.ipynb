{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "# class LogTransformer(BaseEstimator, TransformerMixin):\n",
    "#     \"\"\"\n",
    "#     Log transforming\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, copy=None):\n",
    "#         self.copy = copy\n",
    "\n",
    "#     def fit(self, X, y=None):\n",
    "#         return self\n",
    "\n",
    "#     def transform(self, X, y=None, copy=None):\n",
    "#         return np.log(X + 1)\n",
    "\n",
    "#     def fit_transform(self, X, y=None):\n",
    "#         return self.fit(X, y).transform(X, y)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "class LogTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Log transforming\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return np.log(X + 1)\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.fit(X, y).transform(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from yaml import load as yaml_load, FullLoader\n",
    "import pickle\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RS=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logger import logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((297, 14), (222, 14), (75, 14))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/raw/heart_cleveland_upload.csv')\n",
    "df_train, df_oos = train_test_split(df, stratify=df['condition'], test_size=0.25, random_state=RS)\n",
    "df.shape, df_train.shape, df_oos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('data/raw/train.csv', index=False)\n",
    "df_oos.to_csv('data/raw/oos.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = df_train.drop(columns=['condition']), df_train['condition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = df_oos.drop(columns=['condition']), df_oos['condition']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parameters search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipe(clf_name, r_state):\n",
    "    \"\"\"\n",
    "    Формируем модель с указанными гиперпараметрами \n",
    "    \"\"\" \n",
    "    \n",
    "    if clf_name == 'logreg':\n",
    "        classifier = LogisticRegression(class_weight='balanced',\n",
    "                                        solver='saga',\n",
    "                                        n_jobs=-1,\n",
    "                                        random_state=r_state)\n",
    "        \n",
    "    elif clf_name == 'svm':\n",
    "        classifier = svm.SVC(random_state=r_state)\n",
    "        \n",
    "    else: \n",
    "        raise KeyError('Unknown classifier: {}'.format(clf_name))\n",
    "        \n",
    "    \n",
    "    pipe = Pipeline([\n",
    "                            ('log_scaler', LogTransformer()),\n",
    "                            ('clf', classifier)\n",
    "    ])\n",
    "    \n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_range_fl = [1.0, 0.5]\n",
    "\n",
    "logreg_params = [{'clf__penalty': ['l1', 'l2'],\n",
    "                'clf__C': param_range_fl,\n",
    "                'clf__solver': ['liblinear']}] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_range = [9, 10]\n",
    "\n",
    "svm_params = [{'clf__kernel': ['linear', 'rbf'], \n",
    "        'clf__C': param_range}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {'logreg': logreg_params, \n",
    "               'svm': svm_params\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logreg': [{'clf__penalty': ['l1', 'l2'],\n",
       "   'clf__C': [1.0, 0.5],\n",
       "   'clf__solver': ['liblinear']}],\n",
       " 'svm': [{'clf__kernel': ['linear', 'rbf'], 'clf__C': [9, 10]}]}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = 'svm'\n",
    "clf = 'logreg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "RS=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = build_pipe(clf, r_state=RS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('log_scaler', LogTransformer()),\n",
       "                ('clf',\n",
       "                 LogisticRegression(class_weight='balanced', n_jobs=-1,\n",
       "                                    random_state=42, solver='saga'))])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'clf__penalty': ['l1', 'l2'],\n",
       "  'clf__C': [1.0, 0.5],\n",
       "  'clf__solver': ['liblinear']}]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_space = classifiers[clf]\n",
    "search_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(estimator=pipe,\n",
    "                  param_grid=search_space,\n",
    "                  scoring='accuracy', \n",
    "                  cv=10, \n",
    "                  n_jobs=-1, \n",
    "                  verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('log_scaler', LogTransformer()),\n",
       "                                       ('clf',\n",
       "                                        LogisticRegression(class_weight='balanced',\n",
       "                                                           n_jobs=-1,\n",
       "                                                           random_state=42,\n",
       "                                                           solver='saga'))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'clf__C': [1.0, 0.5], 'clf__penalty': ['l1', 'l2'],\n",
       "                          'clf__solver': ['liblinear']}],\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train logreg model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:logger:Train logreg model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n",
      "Best params are : {'clf__C': 0.5, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:logger:Best params are : {'clf__C': 0.5, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best training accuracy: 0.829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:logger:Best training accuracy: 0.829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy score for best params: 0.893 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:logger:Test set accuracy score for best params: 0.893 \n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Train %s model ...\" % clf)\n",
    "# print('\\nEstimator: %s' % grid_dict[idx])\n",
    "gs.fit(X_train, y_train)\n",
    "logger.info(\"Best params are : %s\" % gs.best_params_)\n",
    "# Best training data accuracy\n",
    "logger.info('Best training accuracy: %.3f' % gs.best_score_)\n",
    "# Predict on test data with best params\n",
    "y_pred = gs.predict(X_test)\n",
    "# Test data accuracy of model with best params\n",
    "logger.info('Test set accuracy score for best params: %.3f ' % accuracy_score(y_test, y_pred))\n",
    "# Track best (highest test accuracy) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__C': 0.5, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = gs.best_params_\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('log_scaler', LogTransformer()),\n",
       "                ('clf',\n",
       "                 LogisticRegression(C=0.5, class_weight='balanced', n_jobs=-1,\n",
       "                                    random_state=42, solver='liblinear'))])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.set_params(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('log_scaler', LogTransformer()),\n",
       "                ('clf',\n",
       "                 LogisticRegression(C=0.5, class_weight='balanced', n_jobs=-1,\n",
       "                                    random_state=42, solver='liblinear'))])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train = model.predict(X_train)\n",
    "preds_oos = model.predict(X_test)\n",
    "# preds_oot = model.predict(X_oot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_f1_macro = accuracy_score(y_train, preds_train)\n",
    "oos_f1_macro = accuracy_score(y_test, preds_oos)\n",
    "# oot_f1_macro = f1_score(y_oot, preds_oot, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1 macro= 0.8378378378378378\n",
      "Out of sample F1 macro= 0.8933333333333333\n"
     ]
    }
   ],
   "source": [
    "print('Train F1 macro=', train_f1_macro)\n",
    "# print('Cross Validation F1 macro=', model.best_score_, 'std=', model.cv_results_['std_test_score'][model.best_index_])\n",
    "print('Out of sample F1 macro=', oos_f1_macro)\n",
    "# print('Out of time F1 macro=', oot_f1_macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "pickle.dump(gs.best_estimator_, open(config.model_params['MODEL_PATH'], 'wb'))\n",
    "print('Обученная модель сохранена {}'.format(config.model_params['MODEL_PATH']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Out of sample classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.97      0.91        40\n",
      "           1       0.97      0.80      0.88        35\n",
      "\n",
      "    accuracy                           0.89        75\n",
      "   macro avg       0.91      0.89      0.89        75\n",
      "weighted avg       0.90      0.89      0.89        75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, preds_oos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
